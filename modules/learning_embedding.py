import torch.nn as nn

class Embedding(nn.Module):
    def __init__(self, vocab_size, hidden_size=768, max_position_embeddings=512):
        super(self, Embedding).__init__()
        pass

    def forward(self, x):
        pass