qwen3结构图：https://zhuanlan.zhihu.com/p/1902019286836449827

huggingface: https://huggingface.co/Qwen/Qwen3-30B-A3B-Thinking-2507

讲解：https://zhuanlan.zhihu.com/p/1902677188064567603

Qwen3 的成功确实不是偶然，它在**模型架构**、**训练策略**、**数据处理**和**效率优化**等方面都进行了精心的设计和创新。虽然你主要关注模型结构和训练方式，但它的成功是这些因素共同作用的结果。

下面这个表格汇总了其主要特点，之后我会进一步解释。

| 方面                 | Qwen3 的关键设计/策略                                      | 带来的优势                                                 |
| :------------------- | :--------------------------------------------------------- | :--------------------------------------------------------- |
| 🧠 **模型架构**      | 混合专家模型 (MoE)                                         | 大幅降低激活参数量，提升计算效率                     |
|                      | 混合注意力机制 (Gated DeltaNet + 标准注意力)               | 兼顾长上下文处理效率与强大的信息召回能力               |
|                      | 思考模式 (Thinking) 与非思考模式 (Non-thinking) 的动态切换 | 根据任务复杂度灵活分配计算资源，平衡响应速度与答案质量 |
| 📚 **训练策略**      | 三阶段预训练 (通用知识 → 推理强化 → 长上下文扩展)          | 循序渐进地构建模型能力，基础更扎实                     |
|                      | 多阶段后训练 (包括强化学习)                                | 精细化微调，更好地对齐人类偏好，提升指令遵循和推理能力   |
|                      | 多Token预测 (MTP) 机制                                     | 提升训练效率及推理速度                               |
| 🌍 **数据处理**      | 大规模、高质量、多语言的预训练数据 (36T Tokens, 119种语言) | 知识丰富，跨语言理解能力强                             |
|                      | 合成数据生成                                              | 针对性增强模型在特定领域（如数学、编程）的能力         |
| ⚡ **效率优化**      | 极稀疏的MoE激活 (如1:50)                                   | 显著降低训练与推理成本                               |
|                      | 一系列训练稳定性优化 (如Zero-Centered Norm)                | 支持大规模模型稳定训练                               |

### 🧠 匠心独运的模型架构

Qwen3 在模型结构上下了不少功夫，旨在**高效地提升模型能力**。

1.  **混合专家模型 (MoE)**：Qwen3 的 MoE 模型（如 30B-A3B 和 235B-A22B）采用了**高稀疏度的专家网络**。这意味着对于每个输入，模型只激活一小部分专家（例如 30B-A3B 仅激活约 30 亿参数），却能拥有庞大的总参数量（如 235B-A22B 总参数量达 2350 亿）。这样做的好处是**在保持强大模型能力的同时，大幅降低了计算和存储开销**。
2.  **混合注意力机制**：为了更高效地处理长上下文，Qwen3-Next 引入了 **Gated DeltaNet（线性注意力）和标准注意力的混合机制**（通常是 75% 的层使用 Gated DeltaNet，25% 的层保留标准注意力）。Gated DeltaNet 能**高效处理长序列**，而标准注意力利于**捕捉复杂的全局依赖关系**。这种混合方式旨在**兼顾长上下文处理的效率和模型的表现力**。此外，在标准注意力层中，还采用了**输出门控**、**更大的注意力头维度**以及**部分旋转位置编码**等优化技术，以进一步提升性能和外推能力。
3.  **动态思考模式**：这是 Qwen3 一个颇具特色的设计。模型可以根据问题的复杂程度，**动态地在“思考模式”（Thinking）和“非思考模式”（Non-thinking）之间切换**。对于复杂问题，模型会进入“思考模式”，生成逐步推理的中间链（通常被封装在 `<think>` 标签内），最后再给出最终答案。对于简单问题，则快速响应。这种机制允许用户**在效果、成本和时间之间进行灵活的权衡**。

### 📚 精细化的训练策略

Qwen3 的训练并非一蹴而就，而是分阶段、有重点地逐步构建模型能力。

1.  **三阶段预训练**：
    *   **通用知识学习 (S1)**：在超过 30万亿 token 的大规模、多语言数据（涵盖 119 种语言）上进行训练，序列长度为 4K，为模型打下**坚实的语言理解和世界知识基础**。
    *   **推理能力强化 (S2)**：增加 STEM、编程、推理和合成数据的比例，使用约 5万亿高质量 token 进一步训练。此阶段**重点提升模型的逻辑推理和代码生成能力**。
    *   **长上下文扩展 (S3)**：使用序列长度最高达 32K 的高质量长文本语料库进行训练，并采用 **ABF（调整 RoPE 基频）、YARN 和 Dual Chunk Attention (DCA) 等技术**，显著**扩展模型的有效上下文处理长度**，使其能够理解更长的文档并进行长程推理。

2.  **多阶段后训练**：预训练后的模型还需经过精细化的后训练才能更好地与人类对齐。Qwen3 的后训练包括：
    *   **长链推理冷启动**：微调多样化的推理数据，让模型具备处理复杂任务的基本能力。
    *   **强化学习 (RL)**：利用强化学习进一步**提升模型的推理能力和输出质量**。
    *   **思考模式与非思考模式融合**：训练模型掌握动态切换推理模式的能力。
    *   **通用任务强化学习**：对大量常见任务进行强化学习微调，确保模型在各种应用场景下都能灵活应对。

3.  **多Token预测 (MTP)**：Qwen3-Next 引入了原生的多Token预测机制。这意味着模型在训练时**同时预测后续多个 token**，而不仅仅是下一个 token。这不仅能提升**训练效率**，更重要的是能**显著加速推理过程**（例如提高 Speculative Decoding 的接受率）。

### 🌍 大规模与高质量的数据处理

数据是大模型的“粮食”，Qwen3 在数据方面同样投入巨大。

1.  **海量多语种预训练数据**：Qwen3 的预训练数据规模达到了 **36万亿 token**，并支持 **119 种语言和方言**。这为模型提供了丰富的知识储备和强大的跨语言理解能力。
2.  **高质量数据生成与过滤**：除了从互联网收集数据，团队还利用 Qwen2.5-VL 从 PDF 等文档中提取文本，并用 Qwen2.5 模型优化其质量。此外，还使用 Qwen2.5-Math 和 Qwen2.5-Coder 等模型**合成了数万亿 token 的高质量数学、编程、指令和问答对等合成数据**，针对性增强模型在特定领域的能力。

### ⚡ 极致的效率优化

Qwen3 的成功也得益于其在提升效率和稳定性方面的多项技术创新。

1.  **极致的稀疏激活**：Qwen3-Next 的 MoE 架构实现了极高的稀疏度，例如总参数量 80B 的模型每次推理**仅激活约 3B 参数（激活比例低至 3.75%）**。这直接转化为**训练和推理成本的数量级降低**（据报道，训练成本可降 9 成，长文本推理吞吐提升 10 倍）。
2.  **训练稳定性优化**：为了确保大规模模型训练的稳定性，Qwen3-Next 采用了如 **Zero-Centered RMSNorm 并对 norm weight 施加 weight decay** 等技术，防止数值不稳定。同时，在 **MoE router 初始化时进行归一化**，确保专家被公平选择，促进训练稳定性。

### 💡 总结

Qwen3 的成功可以归结为：它并**不单纯追求参数规模的无限扩大**，而是通过**混合专家模型 (MoE)**、**混合注意力机制** 和**动态思考模式** 等**精巧的架构设计**，在保持强大性能的同时极致地提升了效率。再结合**三阶段预训练**、**多阶段后训练** 和**多Token预测** 等**精细化的训练策略**，以及**海量、高质量、多语言的数据**，共同造就了其卓越的综合能力。

这些技术进步使得像 Qwen3 这样的模型能够在性能、效率和实用性之间取得更好的平衡，让强大的 AI 能力更容易被广泛获取和应用。